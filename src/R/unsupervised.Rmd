---
title: "Unsupervised learning"
output: html_notebook
---

# Unsupervised Learning

## Required Packages
```{r}
  require("clusterCrit")
  require("gplots")
  require("fpc")
```

## Load and scale data

```{r}
  data <- read.csv("../data sets/food.csv", row.names = 1)
  fds <- scale(data)
```

## Clustering
```{r}

# Initialize lists to store k-means models and criteria indices
set.seed(123)
kmc <- list()
ci <- numeric()

# Loop over different numbers of clusters
for (k in 2:5) {

  # Perform k-means clustering
  kmc[[k]] <- kmeans(fds, k)
  ci[k] <- clusterCrit::intCriteria(fds, kmc[[k]]$cluster, "Silhouette")
  
  # Print the current k value and criterion index for each k
  print(k)
  print(ci[k])
}

#result: k = 4 has the lowest value out of the 4 options
  kmc4 <- kmeans(fds, 4)
  ci <- clusterCrit::intCriteria(fds,kmc4$cluster, "Silhouette")
  ci
```

## PCA and Visualization
```{r}
  pca <- princomp(fds)
  data_red <- pca$scores[,1:2]
  data_red <- data_red * -1
  plot(data_red[,"Comp.1"], data_red[,"Comp.2"], col=(kmc4$cluster))
  text(data_red[,"Comp.1"], data_red[,"Comp.2"], labels = rownames(fds), cex = 0.5)
```

### Hierarchical Clustering
```{r}
  hcf <- hclust(dist(fds))
  plot(hcf)
```

### Heatmap
```{r}
  heatmap.2(fds, scale="none")
```

## Density based clustering
```{r}
  dbc <- dbscan(fds, eps=2, MinPts = 3)
  plot(data_red[,"Comp.1"], data_red[,"Comp.2"], col=(dbc$cluster))
  text(data_red[,"Comp.1"], data_red[,"Comp.2"], labels = rownames(fds), cex = 0.5)
```